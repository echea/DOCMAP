@article{ganesan_computer-aided_2013,
	title = {Computer-{Aided} {Breast} {Cancer} {Detection} {Using} {Mammograms}: {A} {Review}},
	volume = {6},
	issn = {1937-3333},
	shorttitle = {Computer-{Aided} {Breast} {Cancer} {Detection} {Using} {Mammograms}},
	doi = {10.1109/RBME.2012.2232289},
	abstract = {The American Cancer Society (ACS) recommends women aged 40 and above to have a mammogram every year and calls it a gold standard for breast cancer detection. Early detection of breast cancer can improve survival rates to a great extent. Inter-observer and intra-observer errors occur frequently in analysis of medical images, given the high variability between interpretations of different radiologists. Also, the sensitivity of mammographic screening varies with image quality and expertise of the radiologist. So, there is no golden standard for the screening process. To offset this variability and to standardize the diagnostic procedures, efforts are being made to develop automated techniques for diagnosis and grading of breast cancer images. A few papers have documented the general trend of computer-aided diagnosis of breast cancer, making a broad study of the several techniques involved. But, there is no definitive documentation focusing on the mathematical techniques used in breast cancer detection. This review aims at providing an overview about recent advances and developments in the field of Computer-Aided Diagnosis (CAD) of breast cancer using mammograms, specifically focusing on the mathematical aspects of the same, aiming to act as a mathematical primer for intermediates and experts in the field.},
	journal = {IEEE Reviews in Biomedical Engineering},
	author = {Ganesan, K. and Acharya, U. R. and Chua, C. K. and Min, L. C. and Abraham, K. T. and Ng, K. H.},
	year = {2013},
	keywords = {American Cancer Society, Biomedical imaging, breast cancer, breast cancer image grading, Breast Neoplasms, CAD, cancer, classifiers, computer-aided breast cancer detection, Computer-aided diagnosis, computer-aided diagnosis (CAD), diagnostic procedures, digital mammography, Feature extraction, feature extraction techniques, Female, gynaecology, Humans, image quality, inter-observer errors, intra-observer errors, mammograms, mammographic screening sensitivity, mammography, mathematical techniques, medical diagnostic computing, medical image analysis, Medical tests, Noise measurement, Radiographic Image Interpretation, Computer-Assisted, radiologist expertise, radiologists, review, reviews, screening process, Wavelet transforms},
	pages = {77--98},
	file = {2013_Ganesan et al_Computer-Aided Breast Cancer Detection Using Mammograms.pdf:files/53/2013_Ganesan et al_Computer-Aided Breast Cancer Detection Using Mammograms.pdf:application/pdf}
}

@article{sahiner_classification_1996,
	title = {Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images},
	volume = {15},
	issn = {0278-0062},
	shorttitle = {Classification of mass and normal breast tissue},
	doi = {10.1109/42.538937},
	abstract = {The authors investigated the classification of regions of interest (ROI's) on mammograms as either mass or normal tissue using a convolution neural network (CNN). A CNN is a backpropagation neural network with two-dimensional (2-D) weight kernels that operate on images. A generalized, fast and stable implementation of the CNN was developed. The input images to the CNN were obtained from the ROI's using two techniques. The first technique employed averaging and subsampling. The second technique employed texture feature extraction methods applied to small subregions inside the ROI. Features computed over different subregions were arranged as texture images, which were subsequently used as CNN inputs. The effects of CNN architecture and texture feature parameters on classification accuracy were studied. Receiver operating characteristic (ROC) methodology was used to evaluate the classification accuracy. A data set consisting of 168 ROIs containing biopsy-proven masses and 504 ROI's containing normal breast tissue was extracted from 168 mammograms by radiologists experienced in mammography. This data set was used for training and testing the CNN. With the best combination of CNN architecture and texture feature parameters, the area under the test ROC curve reached 0.87, which corresponded to a true-positive fraction of 90\% at a false positive fraction of 31\%. The authors' results demonstrate the feasibility of using a CNN for classification of masses and normal tissue on mammograms},
	number = {5},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Sahiner, B. and Chan, Heang-Ping and Petrick, N. and Wei, Datong and Helvie, M. A. and Adler, D. D. and Goodsitt, M. M.},
	month = oct,
	year = {1996},
	keywords = {Backpropagation, biopsy-proven masses, breast cancer, Breast tissue, Cellular neural networks, Computer architecture, Convolution, convolution neural network, diagnostic radiography, Feature extraction, image classification, image texture, Kernel, mammograms, mass classification, medical diagnostic imaging, medical image processing, neural nets, Neural networks, normal breast tissue, regions of interest, spatial domain images, Testing, texture images, Two dimensional displays, two-dimensional weight kernels},
	pages = {598--610},
	file = {1996_Sahiner et al_Classification of mass and normal breast tissue.pdf:files/37/1996_Sahiner et al_Classification of mass and normal breast tissue.pdf:application/pdf}
}

@article{tang_computer-aided_2009,
	title = {Computer-{Aided} {Detection} and {Diagnosis} of {Breast} {Cancer} {With} {Mammography}: {Recent} {Advances}},
	volume = {13},
	issn = {1089-7771},
	shorttitle = {Computer-{Aided} {Detection} and {Diagnosis} of {Breast} {Cancer} {With} {Mammography}},
	doi = {10.1109/TITB.2008.2009441},
	abstract = {Breast cancer is the second-most common and leading cause of cancer death among women. It has become a major health issue in the world over the past 50 years, and its incidence has increased in recent years. Early detection is an effective way to diagnose and manage breast cancer. Computer-aided detection or diagnosis (CAD) systems can play a key role in the early detection of breast cancer and can reduce the death rate among women with breast cancer. The purpose of this paper is to provide an overview of recent advances in the development of CAD systems and related techniques. We begin with a brief introduction to some basic concepts related to breast cancer detection and diagnosis. We then focus on key CAD techniques developed recently for breast cancer, including detection of calcifications, detection of masses, detection of architectural distortion, detection of bilateral asymmetry, image enhancement, and image retrieval.},
	number = {2},
	journal = {IEEE Transactions on Information Technology in Biomedicine},
	author = {Tang, J. and Rangayyan, R. M. and Xu, J. and Naqa, I. E. and Yang, Y.},
	month = mar,
	year = {2009},
	keywords = {architectural distortion detection, artificial intelligence, bilateral asymmetry, breast cancer, breast cancer diagnosis, Breast Neoplasms, calcification detection, cancer, computer-aided detection or diagnosis (CAD), computer-aided detection system, Diagnosis, Computer-Assisted, diagnostic radiography, Female, Humans, image enhancement, image retrieval, key CAD techniques, mammography, mass detection, medical image processing, Radiographic Image Enhancement, tumours},
	pages = {236--251},
	file = {2009_Tang et al_Computer-Aided Detection and Diagnosis of Breast Cancer With Mammography.pdf:files/42/2009_Tang et al_Computer-Aided Detection and Diagnosis of Breast Cancer With Mammography.pdf:application/pdf}
}

@misc{_convolutional_2016,
	title = {Convolutional neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&oldid=715827194},
	abstract = {In machine learning, a convolutional neural network (CNN, or ConvNet) is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that they respond to overlapping regions tiling the visual field. Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons designed to use minimal amounts of preprocessing. They have wide applications in image and video recognition, recommender systems and natural language processing.},
	language = {en},
	urldate = {2016-04-19},
	journal = {Wikipedia, the free encyclopedia},
	month = apr,
	year = {2016},
	note = {Page Version ID: 715827194}
}

@article{arevalo_representation_2016,
	title = {Representation learning for mammography mass lesion classification with convolutional neural networks},
	volume = {127},
	issn = {0169-2607},
	url = {http://www.sciencedirect.com/science/article/pii/S0169260715300110},
	doi = {10.1016/j.cmpb.2015.12.014},
	abstract = {Background and objective
The automatic classification of breast imaging lesions is currently an unsolved problem. This paper describes an innovative representation learning framework for breast cancer diagnosis in mammography that integrates deep learning techniques to automatically learn discriminative features avoiding the design of specific hand-crafted image-based feature detectors.
Methods
A new biopsy proven benchmarking dataset was built from 344 breast cancer patients’ cases containing a total of 736 film mammography (mediolateral oblique and craniocaudal) views, representative of manually segmented lesions associated with masses: 426 benign lesions and 310 malignant lesions. The developed method comprises two main stages: (i) preprocessing to enhance image details and (ii) supervised training for learning both the features and the breast imaging lesions classifier. In contrast to previous works, we adopt a hybrid approach where convolutional neural networks are used to learn the representation in a supervised way instead of designing particular descriptors to explain the content of mammography images.
Results
Experimental results using the developed benchmarking breast cancer dataset demonstrated that our method exhibits significant improved performance when compared to state-of-the-art image descriptors, such as histogram of oriented gradients (HOG) and histogram of the gradient divergence (HGD), increasing the performance from 0.787 to 0.822 in terms of the area under the ROC curve (AUC). Interestingly, this model also outperforms a set of hand-crafted features that take advantage of additional information from segmentation by the radiologist. Finally, the combination of both representations, learned and hand-crafted, resulted in the best descriptor for mass lesion classification, obtaining 0.826 in the AUC score.
Conclusions
A novel deep learning based framework to automatically address classification of breast mass lesions in mammography was developed.},
	urldate = {2016-04-04},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Arevalo, John and González, Fabio A. and Ramos-Pollán, Raúl and Oliveira, Jose L. and Guevara Lopez, Miguel Angel},
	month = apr,
	year = {2016},
	keywords = {breast cancer, Computer-aided diagnosis, Convolutional neural networks, feature learning, mammography},
	pages = {248--257},
	file = {2016_Arevalo et al_Representation learning for mammography mass lesion classification with.pdf:files/45/2016_Arevalo et al_Representation learning for mammography mass lesion classification with.pdf:application/pdf}
}

@article{jiao_deep_2016,
	title = {A deep feature based framework for breast masses classification},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231216003611},
	doi = {10.1016/j.neucom.2016.02.060},
	abstract = {Characteristic classification of mass plays a role of vital importance in diagnosis of breast cancer. The existing computer aided diagnosis (CAD) methods used to benefit a lot from low-level or middle-level features which are not that good at the simulation of real diagnostic processes, adding difficulties in improving the classification performance. In this paper, we design a deep feature based framework for breast mass classification task. It mainly contains a convolutional neural network (CNN) and a decision mechanism. Combining intensity information and deep features automatically extracted by the trained CNN from the original image, our proposed method could better simulate the diagnostic procedure operated by doctors and achieved state-of-art performance. In this framework, doctors׳ global and local impressions left by mass images were represented by deep features extracted from two different layers called high-level and middle-level features. Meanwhile, the original images were regarded as detailed descriptions of the breast mass. Then, classifiers based on features above were used in combination to predict classes of test images. And outcomes of classifiers based on different features were analyzed jointly to determine the types of test images. With the help of two kinds of feature visualization methods, deep features extracted from different layers illustrate effective in classification performance and diagnosis simulation. In addition, our method was applied to DDSM dataset and achieved high accuracy under two objective evaluation measures.},
	urldate = {2016-04-04},
	journal = {Neurocomputing},
	author = {Jiao, Zhicheng and Gao, Xinbo and Wang, Ying and Li, Jie},
	month = feb,
	year = {2016},
	keywords = {Breast mass classification, Computer-aided diagnosis, Convolutional neural network, Deep learning, Feature visualization},
	file = {Jiao et al_A deep feature based framework for breast masses classification.pdf:files/48/Jiao et al_A deep feature based framework for breast masses classification.pdf:application/pdf}
}

@inproceedings{ertosun_probabilistic_2015,
	title = {Probabilistic visual search for masses within mammography images using deep learning},
	doi = {10.1109/BIBM.2015.7359868},
	abstract = {We developed a deep learning-based visual search system for the task of automated search and localization of masses in whole mammography images. The system consists of two modules: a classification engine and a localization engine. It first classifies mammograms as containing a mass or no mass using a deep learning classifier, and then localizes the mass(es) within the image using a regional probabilistic approach based on a deep learning network. We obtained 85\% accuracy for the task of identifying images that contain a mass, and we were able to localize 85\% of the masses at an average of 0.9 false positives per image. Our system has the advantages of being able to work with an entire mammography image as input without the need for image segmentation or other pre-processing steps, such as cropping or tiling the image, and it is based on deep learning with unsupervised feature discovery, so it does not require pre-defined and hand-crafted image features.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	author = {Ertosun, M. G. and Rubin, D. L.},
	month = nov,
	year = {2015},
	keywords = {automated search, biomedical engineering, Breast, breast cancer, CAD, classification, classification engine, Deep learning, deep learning-based visual search system, deep learning classifier, deep learning network, Detection, Engines, Informatics, learning (artificial intelligence), localization engine, mammography, mammography images, mass localization, Visualization, Visual Search},
	pages = {1310--1315},
	file = {2015_Ertosun_Rubin_Probabilistic visual search for masses within mammography images using deep.pdf:files/51/2015_Ertosun_Rubin_Probabilistic visual search for masses within mammography images using deep.pdf:application/pdf}
}

@inproceedings{arevalo_convolutional_2015,
	title = {Convolutional neural networks for mammography mass lesion classification},
	doi = {10.1109/EMBC.2015.7318482},
	abstract = {Feature extraction is a fundamental step when mammography image analysis is addressed using learning based approaches. Traditionally, problem dependent handcrafted features are used to represent the content of images. An alternative approach successfully applied in other domains is the use of neural networks to automatically discover good features. This work presents an evaluation of convolutional neural networks to learn features for mammography mass lesions before feeding them to a classification stage. Experimental results showed that this approach is a suitable strategy outperforming the state-of-the-art representation from 79.9\% to 86\% in terms of area under the ROC curve.},
	booktitle = {2015 37th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Arevalo, J. and González, F. A. and Ramos-Pollán, R. and Oliveira, J. L. and Lopez, M. A. Guevara},
	month = aug,
	year = {2015},
	keywords = {area under the ROC curve, breast cancer, classification stage, content representation, Convolution, Convolutional neural networks, Feature extraction, image classification, image representation, learning (artificial intelligence), learning based approaches, Lesions, Machine learning, mammography, mammography image analysis, mammography mass lesion classification, medical image processing, neural nets, problem dependent handcrafted features, sensitivity analysis, Shape, Training},
	pages = {797--800},
	file = {2015_Arevalo et al_Convolutional neural networks for mammography mass lesion classification.pdf:files/54/2015_Arevalo et al_Convolutional neural networks for mammography mass lesion classification.pdf:application/pdf}
}

@inproceedings{cruz-roa_automatic_2014,
	title = {Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks},
	volume = {9041},
	url = {http://dx.doi.org/10.1117/12.2043872},
	doi = {10.1117/12.2043872},
	abstract = {This paper presents a deep learning approach for automatic detection and visual analysis of invasive ductal carcinoma (IDC) tissue regions in whole slide images (WSI) of breast cancer (BCa). Deep learning approaches are learn-from-data methods involving computational modeling of the learning process. This approach is similar to how human brain works using different interpretation levels or layers of most representative and useful features resulting into a hierarchical learned representation. These methods have been shown to outpace traditional approaches of most challenging problems in several areas such as speech recognition and object detection. Invasive breast cancer detection is a time consuming and challenging task primarily because it involves a pathologist scanning large swathes of benign regions to ultimately identify the areas of malignancy. Precise delineation of IDC in WSI is crucial to the subsequent estimation of grading tumor aggressiveness and predicting patient outcome. DL approaches are particularly adept at handling these types of problems, especially if a large number of samples are available for training, which would also ensure the generalizability of the learned features and classifier. The DL framework in this paper extends a number of convolutional neural networks (CNN) for visual semantic analysis of tumor regions for diagnosis support. The CNN is trained over a large amount of image patches (tissue regions) from WSI to learn a hierarchical part-based representation. The method was evaluated over a WSI dataset from 162 patients diagnosed with IDC. 113 slides were selected for training and 49 slides were held out for independent testing. Ground truth for quantitative evaluation was provided via expert delineation of the region of cancer by an expert pathologist on the digitized slides. The experimental evaluation was designed to measure classifier accuracy in detecting IDC tissue regions in WSI. Our method yielded the best quantitative results for automatic detection of IDC regions in WSI in terms of F-measure and balanced accuracy (71.80\%, 84.23\%), in comparison with an approach using handcrafted image features (color, texture and edges, nuclear textural and architecture), and a machine learning classifier for invasive tumor classification using a Random Forest. The best performing handcrafted features were fuzzy color histogram (67.53\%, 78.74\%) and RGB histogram (66.64\%, 77.24\%). Our results also suggest that at least some of the tissue classification mistakes (false positives and false negatives) were less due to any fundamental problems associated with the approach, than the inherent limitations in obtaining a very highly granular annotation of the diseased area of interest by an expert pathologist.},
	urldate = {2016-04-09},
	author = {Cruz-Roa, Angel and Basavanhally, Ajay and González, Fabio and Gilmore, Hannah and Feldman, Michael and Ganesan, Shridar and Shih, Natalie and Tomaszewski, John and Madabhushi, Anant},
	year = {2014},
	pages = {904103--904103--15},
	file = {2014_Cruz-Roa et al_Automatic detection of invasive ductal carcinoma in whole slide images with.pdf:files/59/2014_Cruz-Roa et al_Automatic detection of invasive ductal carcinoma in whole slide images with.pdf:application/pdf}
}

@phdthesis{__2014,
	type = {硕士},
	title = {基于卷积神经网络的深度学习算法与应用研究},
	url = {http://www.cnki.net/KCMS/detail/detail.aspx?QueryID=0&CurRec=1&recid=&filename=1014224654.nh&dbname=CMFD201402&dbcode=CMFD&pr=&urlid=&yx=&v=MjY1MDBGckNVUkx5ZlkrZG1GeS9uVmJ2T1ZGMjZHckc2R3RmSnE1RWJQSVI4ZVgxTHV4WVM3RGgxVDNxVHJXTTE=},
	abstract = {深度学习(DL, Deep Learning)是计算机科学机器学习(ML, Machine Learning)领域中一个新的研究方向,它被引入机器学习使其更接近于最初的目标-人工智能(AI, Artificial Intelligence)。深度学习是学习样本数据的内在规律和表示层次,这些学习过程中获得的信息对诸如文字,图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力,能够识别文字、图像和声音等数据。 	深度学习是一个复杂的机器学习算法,在语音和图像识别方面取得的效果,远远超过先前相关技术。它在搜索技术,数据挖掘,机器学习,机器翻译,自然语言处理,多媒体学习,语音,推荐和个性化技术,以及其他相关领域都取得了很多成果。深度学习使机器模仿视听和思考等人类的活动,解决了很多复杂的模式识别难题,使得人工智能相关技术取得了很大进步。将深度学习与各种实际应用研究相结合也是一项很重要的工作。 	本文整理和总结了国内外关于深度学习的发展历程和最新的研究成果,对人工神经网络及经典的卷积神经网络所涉及到的概念和算法进行了简要介绍,将卷积神经网络算法进行了改进并应用于光学字符识别(OCR, Optical Character Recognition)和交通标示识别(TSR, Traffic sign recognition)问题,分别在理论和应用层面对卷积神经网络的架构和性能进行研究分析。本文的主要工作如下： 	1、在LeNet-5网络模型的基础上进行改进,构造了若干各层具有不同神经元个数和层间连接方式的特征抽取滤波器层的卷积神经网络模型,将各个模型应用到光学数字识别问题上,通过这些不同的卷积神经网络模型在实验中学习过程表现出的特性和识别性能分析比较各种模型的优劣。 	2、通过借鉴自适应增强(Adaboost)的思想,构建了一个多列卷积神经网络模型,并将其应用在交通标示识别实际应用问题中,将数据进行预处理,训练卷积神经网络,实现卷积神经网络对交通标示的高性能识别。 	3、通过实验最终验证卷积神经网络在手写数字识别和交通标示识别问题上的应用可行性。并与其他现有的分类器进行比较,分析卷积神经网络模型在各种实际应用问题上的性能。},
	language = {中文;},
	urldate = {2016-04-19},
	school = {浙江工商大学},
	author = {陈, 先昌},
	year = {2014},
	keywords = {光学字符识别, 交通标示识别, 卷积神经网络, 模式识别, 深度学习, Convolutional neural networks, Deep learning, Optical character recognition, Pattern, recognition, Traffic sign recognition}
}