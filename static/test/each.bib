
@article{bengio_representation_2013,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	volume = {35},
	issn = {0162-8828},
	shorttitle = {Representation {Learning}},
	doi = {10.1109/TPAMI.2013.50},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bengio, Y. and Courville, A. and Vincent, P.},
	month = aug,
	year = {2013},
	keywords = {Abstracts, AI, Algorithms, artificial intelligence, autoencoder, autoencoders, Boltzmann machine, data representation, data structures, Deep learning, density estimation, Feature extraction, feature learning, geometrical connections, Humans, Learning systems, Machine learning, machine learning algorithms, manifold learning, Manifolds, neural nets, Neural networks, Neural Networks (Computer), probabilistic models, probability, representation learning, Speech recognition, unsupervised feature learning, unsupervised learning},
	pages = {1798--1828},
	file = {2013_Bengio et al_Representation Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2013\\2013_Bengio et al_Representation Learning.pdf:application/pdf}
}

@misc{_convolutional_2016,
	title = {Convolutional neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&oldid=715827194},
	abstract = {In machine learning, a convolutional neural network (CNN, or ConvNet) is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that they respond to overlapping regions tiling the visual field. Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons designed to use minimal amounts of preprocessing. They have wide applications in image and video recognition, recommender systems and natural language processing.},
	language = {en},
	urldate = {2016-04-19},
	journal = {Wikipedia, the free encyclopedia},
	month = apr,
	year = {2016},
	note = {Page Version ID: 715827194},
	file = {Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\EXR2JBU4\\index.html:text/html}
}

@article{schmidhuber_deep_2015,
	title = {Deep learning in neural networks: {An} overview},
	volume = {61},
	issn = {0893-6080},
	shorttitle = {Deep learning in neural networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2016-05-01},
	journal = {Neural Networks},
	author = {Schmidhuber, Jürgen},
	month = jan,
	year = {2015},
	keywords = {Deep learning, Evolutionary computation, Reinforcement learning, Supervised learning, unsupervised learning},
	pages = {85--117},
	file = {Schmidhuber_2015_Deep learning in neural networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2015\\Schmidhuber_2015_Deep learning in neural networks.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\ADW9HS9I\\S0893608014002135.html:text/html}
}

@article{srivastava_dropout:_2014,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overfitting}},
	volume = {15},
	issn = {1532-4435},
	shorttitle = {Dropout},
	url = {http://dl.acm.org/citation.cfm?id=2627435.2670313},
	abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
	number = {1},
	urldate = {2016-05-01},
	journal = {J. Mach. Learn. Res.},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	month = jan,
	year = {2014},
	keywords = {Deep learning, model combination, Neural networks, regularization},
	pages = {1929--1958},
	file = {Srivastava et al_2014_Dropout.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2014\\Srivastava et al_2014_Dropout.pdf:application/pdf}
}

@incollection{dosovitskiy_discriminative_2014,
	title = {Discriminative {Unsupervised} {Feature} {Learning} with {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf},
	urldate = {2016-05-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Dosovitskiy, Alexey and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {766--774},
	file = {Dosovitskiy et al_2014_Discriminative Unsupervised Feature Learning with Convolutional Neural Networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2014\\Dosovitskiy et al_2014_Discriminative Unsupervised Feature Learning with Convolutional Neural Networks.pdf:application/pdf;NIPS Snapshort:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\4GG8JAUF\\5548-active-regression-by-stratification.html:text/html}
}

@inproceedings{lee_convolutional_2009,
	address = {New York, NY, USA},
	series = {{ICML} '09},
	title = {Convolutional {Deep} {Belief} {Networks} for {Scalable} {Unsupervised} {Learning} of {Hierarchical} {Representations}},
	isbn = {978-1-60558-516-1},
	url = {http://doi.acm.org/10.1145/1553374.1553453},
	doi = {10.1145/1553374.1553453},
	abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
	urldate = {2016-05-01},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
	year = {2009},
	pages = {609--616},
	file = {Lee et al_2009_Convolutional Deep Belief Networks for Scalable Unsupervised Learning of.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2009\\Lee et al_2009_Convolutional Deep Belief Networks for Scalable Unsupervised Learning of.pdf:application/pdf}
}

@article{lecun_generalization_1989,
	title = {Generalization and network design strategies},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.476.479&rep=rep1&type=pdf},
	urldate = {2016-05-01},
	journal = {Connections in Perspective. North-Holland, Amsterdam},
	author = {LeCun, Yann and {others}},
	year = {1989},
	pages = {143--55},
	file = {LeCun_others_1989_Generalization and network design strategies.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\1989\\LeCun_others_1989_Generalization and network design strategies.pdf:application/pdf}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2016-05-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105},
	file = {Krizhevsky et al_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2012\\Krizhevsky et al_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:application/pdf;NIPS Snapshort:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\27S6CPK5\\4824-imagenet-classification-w.html:text/html}
}

@article{hinton_improving_2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	url = {http://arxiv.org/abs/1207.0580},
	abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
	urldate = {2016-05-01},
	journal = {arXiv:1207.0580 [cs]},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	month = jul,
	year = {2012},
	note = {arXiv: 1207.0580},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\RK3II57N\\1207.html:text/html;Hinton et al_2012_Improving neural networks by preventing co-adaptation of feature detectors.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2012\\Hinton et al_2012_Improving neural networks by preventing co-adaptation of feature detectors.pdf:application/pdf}
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {2D shape variability, Backpropagation, back-propagation, Character recognition, cheque reading, complex decision surface synthesis, Convolution, convolutional neural network character recognizers, document recognition, document recognition systems, Feature extraction, field extraction, gradient-based learning, gradient based learning technique, graph transformer networks, GTN, handwritten character recognition, handwritten digit recognition task, Hidden Markov models, high-dimensional patterns, language modeling, Machine learning, Multi-layer neural network, multilayer neural networks, multilayer perceptrons, multimodule systems, Neural networks, Optical character recognition, Optical character recognition software, Optical computing, Pattern recognition, performance measure minimization, Principal component analysis, segmentation recognition},
	pages = {2278--2324},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\M25PQNGT\\abs_all.html:text/html;Lecun et al_1998_Gradient-based learning applied to document recognition.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\1998\\Lecun et al_1998_Gradient-based learning applied to document recognition.pdf:application/pdf}
}

@article{arel_deep_2010,
	title = {Deep {Machine} {Learning} - {A} {New} {Frontier} in {Artificial} {Intelligence} {Research} [{Research} {Frontier}]},
	volume = {5},
	issn = {1556-603X},
	doi = {10.1109/MCI.2010.938364},
	abstract = {This article provides an overview of the mainstream deep learning approaches and research directions proposed over the past decade. It is important to emphasize that each approach has strengths and "weaknesses, depending on the application and context in "which it is being used. Thus, this article presents a summary on the current state of the deep machine learning field and some perspective into how it may evolve. Convolutional Neural Networks (CNNs) and Deep Belief Networks (DBNs) (and their respective variations) are focused on primarily because they are well established in the deep learning field and show great promise for future work.},
	number = {4},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Arel, I. and Rose, D. C. and Karnowski, T. P.},
	month = nov,
	year = {2010},
	keywords = {artificial intelligence research, belief networks, CNN, Convolutional neural networks, DBN, deep belief networks, deep machine learning approach, learning (artificial intelligence), neural nets},
	pages = {13--18},
	file = {Arel et al_2010_Deep Machine Learning - A New Frontier in Artificial Intelligence Research.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Arel et al_2010_Deep Machine Learning - A New Frontier in Artificial Intelligence Research.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\97CI5236\\abs_all.html:text/html}
}

@article{bengio_representation_2012,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	shorttitle = {Representation {Learning}},
	url = {http://arxiv.org/abs/1206.5538},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	urldate = {2016-05-01},
	journal = {arXiv:1206.5538 [cs]},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.5538},
	keywords = {Computer Science - Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\PTAWIH8C\\1206.html:text/html;Bengio et al_2012_Representation Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2012\\Bengio et al_2012_Representation Learning.pdf:application/pdf}
}

@inproceedings{nair_rectified_2010,
	title = {Rectified linear units improve restricted boltzmann machines},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_NairH10.pdf},
	urldate = {2016-05-01},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Machine} {Learning} ({ICML}-10)},
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	year = {2010},
	pages = {807--814},
	file = {Nair_Hinton_2010_Rectified linear units improve restricted boltzmann machines.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Nair_Hinton_2010_Rectified linear units improve restricted boltzmann machines.pdf:application/pdf}
}

@inproceedings{carreira-perpinan_contrastive_2005,
	title = {On {Contrastive} {Divergence} {Learning}.},
	volume = {10},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829&rep=rep1&type=pdf#page=42},
	urldate = {2016-05-01},
	booktitle = {{AISTATS}},
	publisher = {Citeseer},
	author = {Carreira-Perpinan, Miguel A. and Hinton, Geoffrey},
	year = {2005},
	pages = {33--40},
	file = {Carreira-Perpinan_Hinton_2005_On Contrastive Divergence Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2005\\Carreira-Perpinan_Hinton_2005_On Contrastive Divergence Learning.pdf:application/pdf}
}

@article{bengio_learning_1994,
	title = {Learning long-term dependencies with gradient descent is difficult},
	volume = {5},
	issn = {1045-9227},
	doi = {10.1109/72.279181},
	abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered},
	number = {2},
	journal = {IEEE Transactions on Neural Networks},
	author = {Bengio, Y. and Simard, P. and Frasconi, P.},
	month = mar,
	year = {1994},
	keywords = {Computer networks, Cost function, Delay effects, Discrete transforms, Displays, efficient learning, gradient descent, input/output sequence mapping, Intelligent networks, learning (artificial intelligence), long-term dependencies, Neural networks, Neurofeedback, numerical analysis, prediction problems, Production, production problems, recognition, recurrent neural nets, Recurrent neural networks, recurrent neural network training, temporal contingencies},
	pages = {157--166},
	file = {Bengio et al_1994_Learning long-term dependencies with gradient descent is difficult.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\1994\\Bengio et al_1994_Learning long-term dependencies with gradient descent is difficult.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\W5IRGBDJ\\abs_all.html:text/html}
}

@article{bengio_learning_2009,
	title = {Learning deep architectures for {AI}},
	volume = {2},
	url = {http://dl.acm.org/citation.cfm?id=1658424},
	number = {1},
	urldate = {2016-05-01},
	journal = {Foundations and trends® in Machine Learning},
	author = {Bengio, Yoshua},
	year = {2009},
	pages = {1--127},
	file = {Bengio_2009_Learning deep architectures for AI.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2009\\Bengio_2009_Learning deep architectures for AI.pdf:application/pdf;Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\V3SH6FWC\\citation.html:text/html}
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf},
	urldate = {2016-05-01},
	booktitle = {International conference on artificial intelligence and statistics},
	author = {Glorot, Xavier and Bengio, Yoshua},
	year = {2010},
	pages = {249--256},
	file = {Glorot_Bengio_2010_Understanding the difficulty of training deep feedforward neural networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Glorot_Bengio_2010_Understanding the difficulty of training deep feedforward neural networks.pdf:application/pdf}
}

@inproceedings{jarrett_what_2009,
	title = {What is the best multi-stage architecture for object recognition?},
	doi = {10.1109/ICCV.2009.5459469},
	abstract = {In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63\% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6\%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 ({\textgreater} 65\%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53\%).},
	booktitle = {2009 {IEEE} 12th {International} {Conference} on {Computer} {Vision}},
	author = {Jarrett, K. and Kavukcuoglu, K. and Ranzato, M. and LeCun, Y.},
	month = sep,
	year = {2009},
	keywords = {Brain modeling, Caltech-101, Error analysis, Feature extraction, feature pooling layer, feature rectification, filter bank, Gabor filters, Histograms, Image edge detection, Learning systems, local contrast normalization, multistage architecture, nonlinear transformation, NORB dataset, object recognition, Refining, Supervised learning, unprocessed MNIST dataset, unsupervised learning},
	pages = {2146--2153},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\4826BN4G\\abs_all.html:text/html;Jarrett et al_2009_What is the best multi-stage architecture for object recognition.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2009\\Jarrett et al_2009_What is the best multi-stage architecture for object recognition.pdf:application/pdf}
}

@article{erhan_why_2010,
	title = {Why {Does} {Unsupervised} {Pre}-training {Help} {Deep} {Learning}?},
	volume = {11},
	issn = {1532-4435},
	url = {http://dl.acm.org/citation.cfm?id=1756006.1756025},
	abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.},
	urldate = {2016-05-01},
	journal = {J. Mach. Learn. Res.},
	author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
	month = mar,
	year = {2010},
	pages = {625--660},
	file = {Erhan et al_2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Erhan et al_2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:application/pdf}
}

@article{farabet_learning_2013,
	title = {Learning {Hierarchical} {Features} for {Scene} {Labeling}},
	volume = {35},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.231},
	abstract = {Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320×240 image labeling in less than a second, including feature extraction.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Farabet, C. and Couprie, C. and Najman, L. and LeCun, Y.},
	month = aug,
	year = {2013},
	keywords = {Accuracy, Barcelona dataset, Context, contextual information capturing, Convolutional networks, Deep learning, dense feature vector extraction, Feature extraction, hierarchical feature learning, image classification, Image edge detection, image labeling, image pixel labeling, image segmentation, image texture, Labeling, multiple size region encoding, multiscale convolutional network, near-record accuracy, object category, scene labeling, scene parsing, segmentation components, segmentation tree, shape information capturing, shape recognition, SIFT flow dataset, Stanford background dataset, texture information capturing, transforms, trees (mathematics), Vectors},
	pages = {1915--1929},
	file = {Farabet et al_2013_Learning Hierarchical Features for Scene Labeling.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2013\\Farabet et al_2013_Learning Hierarchical Features for Scene Labeling.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\6268BX6T\\abs_all.html:text/html}
}

@article{bengio_greedy_2007,
	title = {Greedy layer-wise training of deep networks},
	volume = {19},
	url = {https://books.google.com/books?hl=zh-CN&lr=&id=Tbn1l9P1220C&oi=fnd&pg=PA153&dq=greedy+layer-wise+training+of+deep+networks&ots=V3q8Bmps3_&sig=TY9bt9KZNBh4yfiH-PiKCD4JR6s},
	urldate = {2016-05-01},
	journal = {Advances in neural information processing systems},
	author = {Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo and {others}},
	year = {2007},
	pages = {153},
	file = {Bengio et al_2007_Greedy layer-wise training of deep networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2007\\Bengio et al_2007_Greedy layer-wise training of deep networks.pdf:application/pdf}
}


@article{ganesan_computer-aided_2013,
	title = {Computer-{Aided} {Breast} {Cancer} {Detection} {Using} {Mammograms}: {A} {Review}},
	volume = {6},
	issn = {1937-3333},
	shorttitle = {Computer-{Aided} {Breast} {Cancer} {Detection} {Using} {Mammograms}},
	doi = {10.1109/RBME.2012.2232289},
	abstract = {The American Cancer Society (ACS) recommends women aged 40 and above to have a mammogram every year and calls it a gold standard for breast cancer detection. Early detection of breast cancer can improve survival rates to a great extent. Inter-observer and intra-observer errors occur frequently in analysis of medical images, given the high variability between interpretations of different radiologists. Also, the sensitivity of mammographic screening varies with image quality and expertise of the radiologist. So, there is no golden standard for the screening process. To offset this variability and to standardize the diagnostic procedures, efforts are being made to develop automated techniques for diagnosis and grading of breast cancer images. A few papers have documented the general trend of computer-aided diagnosis of breast cancer, making a broad study of the several techniques involved. But, there is no definitive documentation focusing on the mathematical techniques used in breast cancer detection. This review aims at providing an overview about recent advances and developments in the field of Computer-Aided Diagnosis (CAD) of breast cancer using mammograms, specifically focusing on the mathematical aspects of the same, aiming to act as a mathematical primer for intermediates and experts in the field.},
	journal = {IEEE Reviews in Biomedical Engineering},
	author = {Ganesan, K. and Acharya, U. R. and Chua, C. K. and Min, L. C. and Abraham, K. T. and Ng, K. H.},
	year = {2013},
	keywords = {American Cancer Society, Biomedical imaging, breast cancer, breast cancer image grading, Breast Neoplasms, CAD, cancer, classifiers, computer-aided breast cancer detection, Computer-aided diagnosis, computer-aided diagnosis (CAD), diagnostic procedures, digital mammography, Feature extraction, feature extraction techniques, Female, gynaecology, Humans, image quality, inter-observer errors, intra-observer errors, mammograms, mammographic screening sensitivity, mammography, mathematical techniques, medical diagnostic computing, medical image analysis, Medical tests, Noise measurement, Radiographic Image Interpretation, Computer-Assisted, radiologist expertise, radiologists, review, reviews, screening process, Wavelet transforms},
	pages = {77--98},
	file = {2013_Ganesan et al_Computer-Aided Breast Cancer Detection Using Mammograms.pdf:files/53/2013_Ganesan et al_Computer-Aided Breast Cancer Detection Using Mammograms.pdf:application/pdf}
}

@article{sahiner_classification_1996,
	title = {Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images},
	volume = {15},
	issn = {0278-0062},
	shorttitle = {Classification of mass and normal breast tissue},
	doi = {10.1109/42.538937},
	abstract = {The authors investigated the classification of regions of interest (ROI's) on mammograms as either mass or normal tissue using a convolution neural network (CNN). A CNN is a backpropagation neural network with two-dimensional (2-D) weight kernels that operate on images. A generalized, fast and stable implementation of the CNN was developed. The input images to the CNN were obtained from the ROI's using two techniques. The first technique employed averaging and subsampling. The second technique employed texture feature extraction methods applied to small subregions inside the ROI. Features computed over different subregions were arranged as texture images, which were subsequently used as CNN inputs. The effects of CNN architecture and texture feature parameters on classification accuracy were studied. Receiver operating characteristic (ROC) methodology was used to evaluate the classification accuracy. A data set consisting of 168 ROIs containing biopsy-proven masses and 504 ROI's containing normal breast tissue was extracted from 168 mammograms by radiologists experienced in mammography. This data set was used for training and testing the CNN. With the best combination of CNN architecture and texture feature parameters, the area under the test ROC curve reached 0.87, which corresponded to a true-positive fraction of 90\% at a false positive fraction of 31\%. The authors' results demonstrate the feasibility of using a CNN for classification of masses and normal tissue on mammograms},
	number = {5},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Sahiner, B. and Chan, Heang-Ping and Petrick, N. and Wei, Datong and Helvie, M. A. and Adler, D. D. and Goodsitt, M. M.},
	month = oct,
	year = {1996},
	keywords = {Backpropagation, biopsy-proven masses, breast cancer, Breast tissue, Cellular neural networks, Computer architecture, Convolution, convolution neural network, diagnostic radiography, Feature extraction, image classification, image texture, Kernel, mammograms, mass classification, medical diagnostic imaging, medical image processing, neural nets, Neural networks, normal breast tissue, regions of interest, spatial domain images, Testing, texture images, Two dimensional displays, two-dimensional weight kernels},
	pages = {598--610},
	file = {1996_Sahiner et al_Classification of mass and normal breast tissue.pdf:files/37/1996_Sahiner et al_Classification of mass and normal breast tissue.pdf:application/pdf}
}

@article{tang_computer-aided_2009,
	title = {Computer-{Aided} {Detection} and {Diagnosis} of {Breast} {Cancer} {With} {Mammography}: {Recent} {Advances}},
	volume = {13},
	issn = {1089-7771},
	shorttitle = {Computer-{Aided} {Detection} and {Diagnosis} of {Breast} {Cancer} {With} {Mammography}},
	doi = {10.1109/TITB.2008.2009441},
	abstract = {Breast cancer is the second-most common and leading cause of cancer death among women. It has become a major health issue in the world over the past 50 years, and its incidence has increased in recent years. Early detection is an effective way to diagnose and manage breast cancer. Computer-aided detection or diagnosis (CAD) systems can play a key role in the early detection of breast cancer and can reduce the death rate among women with breast cancer. The purpose of this paper is to provide an overview of recent advances in the development of CAD systems and related techniques. We begin with a brief introduction to some basic concepts related to breast cancer detection and diagnosis. We then focus on key CAD techniques developed recently for breast cancer, including detection of calcifications, detection of masses, detection of architectural distortion, detection of bilateral asymmetry, image enhancement, and image retrieval.},
	number = {2},
	journal = {IEEE Transactions on Information Technology in Biomedicine},
	author = {Tang, J. and Rangayyan, R. M. and Xu, J. and Naqa, I. E. and Yang, Y.},
	month = mar,
	year = {2009},
	keywords = {architectural distortion detection, artificial intelligence, bilateral asymmetry, breast cancer, breast cancer diagnosis, Breast Neoplasms, calcification detection, cancer, computer-aided detection or diagnosis (CAD), computer-aided detection system, Diagnosis, Computer-Assisted, diagnostic radiography, Female, Humans, image enhancement, image retrieval, key CAD techniques, mammography, mass detection, medical image processing, Radiographic Image Enhancement, tumours},
	pages = {236--251},
	file = {2009_Tang et al_Computer-Aided Detection and Diagnosis of Breast Cancer With Mammography.pdf:files/42/2009_Tang et al_Computer-Aided Detection and Diagnosis of Breast Cancer With Mammography.pdf:application/pdf}
}

@misc{_convolutional_2016,
	title = {Convolutional neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&oldid=715827194},
	abstract = {In machine learning, a convolutional neural network (CNN, or ConvNet) is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that they respond to overlapping regions tiling the visual field. Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons designed to use minimal amounts of preprocessing. They have wide applications in image and video recognition, recommender systems and natural language processing.},
	language = {en},
	urldate = {2016-04-19},
	journal = {Wikipedia, the free encyclopedia},
	month = apr,
	year = {2016},
	note = {Page Version ID: 715827194}
}

@article{arevalo_representation_2016,
	title = {Representation learning for mammography mass lesion classification with convolutional neural networks},
	volume = {127},
	issn = {0169-2607},
	url = {http://www.sciencedirect.com/science/article/pii/S0169260715300110},
	doi = {10.1016/j.cmpb.2015.12.014},
	abstract = {Background and objective
The automatic classification of breast imaging lesions is currently an unsolved problem. This paper describes an innovative representation learning framework for breast cancer diagnosis in mammography that integrates deep learning techniques to automatically learn discriminative features avoiding the design of specific hand-crafted image-based feature detectors.
Methods
A new biopsy proven benchmarking dataset was built from 344 breast cancer patients’ cases containing a total of 736 film mammography (mediolateral oblique and craniocaudal) views, representative of manually segmented lesions associated with masses: 426 benign lesions and 310 malignant lesions. The developed method comprises two main stages: (i) preprocessing to enhance image details and (ii) supervised training for learning both the features and the breast imaging lesions classifier. In contrast to previous works, we adopt a hybrid approach where convolutional neural networks are used to learn the representation in a supervised way instead of designing particular descriptors to explain the content of mammography images.
Results
Experimental results using the developed benchmarking breast cancer dataset demonstrated that our method exhibits significant improved performance when compared to state-of-the-art image descriptors, such as histogram of oriented gradients (HOG) and histogram of the gradient divergence (HGD), increasing the performance from 0.787 to 0.822 in terms of the area under the ROC curve (AUC). Interestingly, this model also outperforms a set of hand-crafted features that take advantage of additional information from segmentation by the radiologist. Finally, the combination of both representations, learned and hand-crafted, resulted in the best descriptor for mass lesion classification, obtaining 0.826 in the AUC score.
Conclusions
A novel deep learning based framework to automatically address classification of breast mass lesions in mammography was developed.},
	urldate = {2016-04-04},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Arevalo, John and González, Fabio A. and Ramos-Pollán, Raúl and Oliveira, Jose L. and Guevara Lopez, Miguel Angel},
	month = apr,
	year = {2016},
	keywords = {breast cancer, Computer-aided diagnosis, Convolutional neural networks, feature learning, mammography},
	pages = {248--257},
	file = {2016_Arevalo et al_Representation learning for mammography mass lesion classification with.pdf:files/45/2016_Arevalo et al_Representation learning for mammography mass lesion classification with.pdf:application/pdf}
}

@article{jiao_deep_2016,
	title = {A deep feature based framework for breast masses classification},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231216003611},
	doi = {10.1016/j.neucom.2016.02.060},
	abstract = {Characteristic classification of mass plays a role of vital importance in diagnosis of breast cancer. The existing computer aided diagnosis (CAD) methods used to benefit a lot from low-level or middle-level features which are not that good at the simulation of real diagnostic processes, adding difficulties in improving the classification performance. In this paper, we design a deep feature based framework for breast mass classification task. It mainly contains a convolutional neural network (CNN) and a decision mechanism. Combining intensity information and deep features automatically extracted by the trained CNN from the original image, our proposed method could better simulate the diagnostic procedure operated by doctors and achieved state-of-art performance. In this framework, doctors׳ global and local impressions left by mass images were represented by deep features extracted from two different layers called high-level and middle-level features. Meanwhile, the original images were regarded as detailed descriptions of the breast mass. Then, classifiers based on features above were used in combination to predict classes of test images. And outcomes of classifiers based on different features were analyzed jointly to determine the types of test images. With the help of two kinds of feature visualization methods, deep features extracted from different layers illustrate effective in classification performance and diagnosis simulation. In addition, our method was applied to DDSM dataset and achieved high accuracy under two objective evaluation measures.},
	urldate = {2016-04-04},
	journal = {Neurocomputing},
	author = {Jiao, Zhicheng and Gao, Xinbo and Wang, Ying and Li, Jie},
	month = feb,
	year = {2016},
	keywords = {Breast mass classification, Computer-aided diagnosis, Convolutional neural network, Deep learning, Feature visualization},
	file = {Jiao et al_A deep feature based framework for breast masses classification.pdf:files/48/Jiao et al_A deep feature based framework for breast masses classification.pdf:application/pdf}
}

@inproceedings{ertosun_probabilistic_2015,
	title = {Probabilistic visual search for masses within mammography images using deep learning},
	doi = {10.1109/BIBM.2015.7359868},
	abstract = {We developed a deep learning-based visual search system for the task of automated search and localization of masses in whole mammography images. The system consists of two modules: a classification engine and a localization engine. It first classifies mammograms as containing a mass or no mass using a deep learning classifier, and then localizes the mass(es) within the image using a regional probabilistic approach based on a deep learning network. We obtained 85\% accuracy for the task of identifying images that contain a mass, and we were able to localize 85\% of the masses at an average of 0.9 false positives per image. Our system has the advantages of being able to work with an entire mammography image as input without the need for image segmentation or other pre-processing steps, such as cropping or tiling the image, and it is based on deep learning with unsupervised feature discovery, so it does not require pre-defined and hand-crafted image features.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	author = {Ertosun, M. G. and Rubin, D. L.},
	month = nov,
	year = {2015},
	keywords = {automated search, biomedical engineering, Breast, breast cancer, CAD, classification, classification engine, Deep learning, deep learning-based visual search system, deep learning classifier, deep learning network, Detection, Engines, Informatics, learning (artificial intelligence), localization engine, mammography, mammography images, mass localization, Visualization, Visual Search},
	pages = {1310--1315},
	file = {2015_Ertosun_Rubin_Probabilistic visual search for masses within mammography images using deep.pdf:files/51/2015_Ertosun_Rubin_Probabilistic visual search for masses within mammography images using deep.pdf:application/pdf}
}

@inproceedings{arevalo_convolutional_2015,
	title = {Convolutional neural networks for mammography mass lesion classification},
	doi = {10.1109/EMBC.2015.7318482},
	abstract = {Feature extraction is a fundamental step when mammography image analysis is addressed using learning based approaches. Traditionally, problem dependent handcrafted features are used to represent the content of images. An alternative approach successfully applied in other domains is the use of neural networks to automatically discover good features. This work presents an evaluation of convolutional neural networks to learn features for mammography mass lesions before feeding them to a classification stage. Experimental results showed that this approach is a suitable strategy outperforming the state-of-the-art representation from 79.9\% to 86\% in terms of area under the ROC curve.},
	booktitle = {2015 37th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Arevalo, J. and González, F. A. and Ramos-Pollán, R. and Oliveira, J. L. and Lopez, M. A. Guevara},
	month = aug,
	year = {2015},
	keywords = {area under the ROC curve, breast cancer, classification stage, content representation, Convolution, Convolutional neural networks, Feature extraction, image classification, image representation, learning (artificial intelligence), learning based approaches, Lesions, Machine learning, mammography, mammography image analysis, mammography mass lesion classification, medical image processing, neural nets, problem dependent handcrafted features, sensitivity analysis, Shape, Training},
	pages = {797--800},
	file = {2015_Arevalo et al_Convolutional neural networks for mammography mass lesion classification.pdf:files/54/2015_Arevalo et al_Convolutional neural networks for mammography mass lesion classification.pdf:application/pdf}
}

@inproceedings{cruz-roa_automatic_2014,
	title = {Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks},
	volume = {9041},
	url = {http://dx.doi.org/10.1117/12.2043872},
	doi = {10.1117/12.2043872},
	abstract = {This paper presents a deep learning approach for automatic detection and visual analysis of invasive ductal carcinoma (IDC) tissue regions in whole slide images (WSI) of breast cancer (BCa). Deep learning approaches are learn-from-data methods involving computational modeling of the learning process. This approach is similar to how human brain works using different interpretation levels or layers of most representative and useful features resulting into a hierarchical learned representation. These methods have been shown to outpace traditional approaches of most challenging problems in several areas such as speech recognition and object detection. Invasive breast cancer detection is a time consuming and challenging task primarily because it involves a pathologist scanning large swathes of benign regions to ultimately identify the areas of malignancy. Precise delineation of IDC in WSI is crucial to the subsequent estimation of grading tumor aggressiveness and predicting patient outcome. DL approaches are particularly adept at handling these types of problems, especially if a large number of samples are available for training, which would also ensure the generalizability of the learned features and classifier. The DL framework in this paper extends a number of convolutional neural networks (CNN) for visual semantic analysis of tumor regions for diagnosis support. The CNN is trained over a large amount of image patches (tissue regions) from WSI to learn a hierarchical part-based representation. The method was evaluated over a WSI dataset from 162 patients diagnosed with IDC. 113 slides were selected for training and 49 slides were held out for independent testing. Ground truth for quantitative evaluation was provided via expert delineation of the region of cancer by an expert pathologist on the digitized slides. The experimental evaluation was designed to measure classifier accuracy in detecting IDC tissue regions in WSI. Our method yielded the best quantitative results for automatic detection of IDC regions in WSI in terms of F-measure and balanced accuracy (71.80\%, 84.23\%), in comparison with an approach using handcrafted image features (color, texture and edges, nuclear textural and architecture), and a machine learning classifier for invasive tumor classification using a Random Forest. The best performing handcrafted features were fuzzy color histogram (67.53\%, 78.74\%) and RGB histogram (66.64\%, 77.24\%). Our results also suggest that at least some of the tissue classification mistakes (false positives and false negatives) were less due to any fundamental problems associated with the approach, than the inherent limitations in obtaining a very highly granular annotation of the diseased area of interest by an expert pathologist.},
	urldate = {2016-04-09},
	author = {Cruz-Roa, Angel and Basavanhally, Ajay and González, Fabio and Gilmore, Hannah and Feldman, Michael and Ganesan, Shridar and Shih, Natalie and Tomaszewski, John and Madabhushi, Anant},
	year = {2014},
	pages = {904103--904103--15},
	file = {2014_Cruz-Roa et al_Automatic detection of invasive ductal carcinoma in whole slide images with.pdf:files/59/2014_Cruz-Roa et al_Automatic detection of invasive ductal carcinoma in whole slide images with.pdf:application/pdf}
}

@phdthesis{__2014,
	type = {硕士},
	title = {基于卷积神经网络的深度学习算法与应用研究},
	url = {http://www.cnki.net/KCMS/detail/detail.aspx?QueryID=0&CurRec=1&recid=&filename=1014224654.nh&dbname=CMFD201402&dbcode=CMFD&pr=&urlid=&yx=&v=MjY1MDBGckNVUkx5ZlkrZG1GeS9uVmJ2T1ZGMjZHckc2R3RmSnE1RWJQSVI4ZVgxTHV4WVM3RGgxVDNxVHJXTTE=},
	abstract = {深度学习(DL, Deep Learning)是计算机科学机器学习(ML, Machine Learning)领域中一个新的研究方向,它被引入机器学习使其更接近于最初的目标-人工智能(AI, Artificial Intelligence)。深度学习是学习样本数据的内在规律和表示层次,这些学习过程中获得的信息对诸如文字,图像和声音等数据的解释有很大的帮助。它的最终目标是让机器能够像人一样具有分析学习能力,能够识别文字、图像和声音等数据。 	深度学习是一个复杂的机器学习算法,在语音和图像识别方面取得的效果,远远超过先前相关技术。它在搜索技术,数据挖掘,机器学习,机器翻译,自然语言处理,多媒体学习,语音,推荐和个性化技术,以及其他相关领域都取得了很多成果。深度学习使机器模仿视听和思考等人类的活动,解决了很多复杂的模式识别难题,使得人工智能相关技术取得了很大进步。将深度学习与各种实际应用研究相结合也是一项很重要的工作。 	本文整理和总结了国内外关于深度学习的发展历程和最新的研究成果,对人工神经网络及经典的卷积神经网络所涉及到的概念和算法进行了简要介绍,将卷积神经网络算法进行了改进并应用于光学字符识别(OCR, Optical Character Recognition)和交通标示识别(TSR, Traffic sign recognition)问题,分别在理论和应用层面对卷积神经网络的架构和性能进行研究分析。本文的主要工作如下： 	1、在LeNet-5网络模型的基础上进行改进,构造了若干各层具有不同神经元个数和层间连接方式的特征抽取滤波器层的卷积神经网络模型,将各个模型应用到光学数字识别问题上,通过这些不同的卷积神经网络模型在实验中学习过程表现出的特性和识别性能分析比较各种模型的优劣。 	2、通过借鉴自适应增强(Adaboost)的思想,构建了一个多列卷积神经网络模型,并将其应用在交通标示识别实际应用问题中,将数据进行预处理,训练卷积神经网络,实现卷积神经网络对交通标示的高性能识别。 	3、通过实验最终验证卷积神经网络在手写数字识别和交通标示识别问题上的应用可行性。并与其他现有的分类器进行比较,分析卷积神经网络模型在各种实际应用问题上的性能。},
	language = {中文;},
	urldate = {2016-04-19},
	school = {浙江工商大学},
	author = {陈, 先昌},
	year = {2014},
	keywords = {光学字符识别, 交通标示识别, 卷积神经网络, 模式识别, 深度学习, Convolutional neural networks, Deep learning, Optical character recognition, Pattern, recognition, Traffic sign recognition}
}


@inproceedings{marsden_improving_2003,
	address = {Republic of South Africa},
	series = {{SAICSIT} '03},
	title = {Improving the {Usability} of the {Hierarchical} {File} {System}},
	isbn = {978-1-58113-774-3},
	url = {http://dl.acm.org/citation.cfm?id=954014.954027},
	abstract = {Whether you are interested in improving the usability of Linux, Macintosh or Windows, there is one restriction you cannot escape -- the hierarchical file storage system. The notion of files and folders has been with us for so long that it almost seems axiomatic. In this paper we look at the effects on users of forcing a hierarchical classification of files. We also consider how some of the resultant problems can be tackled with a new piece of file browsing software based on the ideas of relational database systems.},
	urldate = {2016-04-08},
	booktitle = {Proceedings of the 2003 {Annual} {Research} {Conference} of the {South} {African} {Institute} of {Computer} {Scientists} and {Information} {Technologists} on {Enablement} {Through} {Technology}},
	publisher = {South African Institute for Computer Scientists and Information Technologists},
	author = {Marsden, Gary and Cairns, David E.},
	year = {2003},
	keywords = {databases, design, file storage, human-computer interaction, human factors, information retrieval, searching},
	pages = {122--129},
	file = {2003_Marsden_Cairns_Improving the Usability of the Hierarchical File System.pdf:files/31/2003_Marsden_Cairns_Improving the Usability of the Hierarchical File System.pdf:application/pdf}
}

@misc{_user_????,
	title = {User interfaces for supporting multiple categorization},
	url = {http://www.academia.edu/2869086/User_interfaces_for_supporting_multiple_categorization},
	abstract = {Abstract: As the amount of information stored on and accessed by computer has increased over the past twenty years, the tools available for organizing and retrieving such information have become outdated. The folder paradigm has dominated existing},
	urldate = {2016-04-08},
	file = {User interfaces for supporting multiple categorization.pdf:files/52/User interfaces for supporting multiple categorization.pdf:application/pdf}
}

@article{karpicke_retrieval_2011,
	title = {Retrieval {Practice} {Produces} {More} {Learning} than {Elaborative} {Studying} with {Concept} {Mapping}},
	volume = {331},
	copyright = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/331/6018/772},
	doi = {10.1126/science.1199327},
	abstract = {Educators rely heavily on learning activities that encourage elaborative studying, whereas activities that require students to practice retrieving and reconstructing knowledge are used less frequently. Here, we show that practicing retrieval produces greater gains in meaningful learning than elaborative studying with concept mapping. The advantage of retrieval practice generalized across texts identical to those commonly found in science education. The advantage of retrieval practice was observed with test questions that assessed comprehension and required students to make inferences. The advantage of retrieval practice occurred even when the criterial test involved creating concept maps. Our findings support the theory that retrieval practice enhances learning by retrieval-specific mechanisms rather than by elaborative study processes. Retrieval practice is an effective tool to promote conceptual learning about science.
Two different ways of thinking through texts are compared for learning value.
Two different ways of thinking through texts are compared for learning value.},
	language = {en},
	number = {6018},
	urldate = {2016-03-27},
	journal = {Science},
	author = {Karpicke, Jeffrey D. and Blunt, Janell R.},
	month = feb,
	year = {2011},
	pmid = {21252317},
	pages = {772--775},
	file = {2011_Karpicke_Blunt_Retrieval Practice Produces More Learning than Elaborative Studying with.pdf:files/42/2011_Karpicke_Blunt_Retrieval Practice Produces More Learning than Elaborative Studying with.pdf:application/pdf}
}

@article{eppler_comparison_2006,
	title = {A {Comparison} between {Concept} {Maps}, {Mind} {Maps}, {Conceptual} {Diagrams}, and {Visual} {Metaphors} as {Complementary} {Tools} for {Knowledge} {Construction} and {Sharing}},
	volume = {5},
	issn = {1473-8716, 1473-8724},
	url = {http://ivi.sagepub.com/content/5/3/202},
	doi = {10.1057/palgrave.ivs.9500131},
	abstract = {In this article, Novak's concept mapping technique is compared to three other types of visualization formats, namely mind maps, conceptual diagrams, and visual metaphors. The application parameters and the respective advantages and disadvantages of each format for learning and knowledge sharing are reviewed and discussed. It is argued that the combination of these four visualization types can play to the strength of each one. The article then provides real-life examples from such a use in undergraduate and graduate university teaching. The results provide first indications that the different visualization formats can be used in complementary ways to enhance motivation, attention, understanding and recall. The implications for a complementary use of these visualization formats in class room and meeting contexts are discussed and a future research agenda in this domain is articulated.},
	language = {en},
	number = {3},
	urldate = {2016-03-27},
	journal = {Information Visualization},
	author = {Eppler, Martin J.},
	month = sep,
	year = {2006},
	keywords = {complementary visualization, Concept map, concept skeleton, conceptual diagram, mind map, visual metaphor},
	pages = {202--210},
	file = {2006_Eppler_A Comparison between Concept Maps, Mind Maps, Conceptual Diagrams, and Visual.pdf:files/36/2006_Eppler_A Comparison between Concept Maps, Mind Maps, Conceptual Diagrams, and Visual.pdf:application/pdf}
}

@article{nesbit_learning_2006,
	title = {Learning {With} {Concept} and {Knowledge} {Maps}: {A} {Meta}-{Analysis}},
	volume = {76},
	issn = {0034-6543, 1935-1046},
	shorttitle = {Learning {With} {Concept} and {Knowledge} {Maps}},
	url = {http://rer.sagepub.com/content/76/3/413},
	doi = {10.3102/00346543076003413},
	abstract = {This meta-analysis reviews experimental and quasi-experimental studies in which students learned by constructing, modifying, or viewing node-link diagrams. Following an exhaustive search for studies meeting specified design criteria, 67 standardized mean difference effect sizes were extracted from 55 studies involving 5,818 participants. Students at levels ranging from Grade 4 to postsecondary used concept maps to learn in domains such as science, psychology, statistics, and nursing. Posttests measured recall and transfer. Across several instructional conditions, settings, and methodological features, the use of concept maps was associated with increased knowledge retention. Mean effect sizes varied from small to large depending on how concept maps were used and on the type of comparison treatment. Significant heterogeneity was found in most subsets.},
	language = {en},
	number = {3},
	urldate = {2016-03-27},
	journal = {Review of Educational Research},
	author = {Nesbit, John C. and Adesope, Olusola O.},
	month = sep,
	year = {2006},
	keywords = {Concept map, graphic organizer, knowledge map, meta-analysis, node-link map},
	pages = {413--448},
	file = {2006_Nesbit_Adesope_Learning With Concept and Knowledge Maps.pdf:files/38/2006_Nesbit_Adesope_Learning With Concept and Knowledge Maps.pdf:application/pdf}
}

@article{__2002,
	title = {基于文献知识单元的知识组织——文献知识库建设研究},
	volume = {20},
	url = {http://www.cqvip.com/qk/90051a/200211/7055944.html},
	number = {11},
	urldate = {2016-04-02},
	journal = {情报科学},
	author = {{曹锦丹}},
	year = {2002},
	pages = {1187--1189},
	file = {2002_曹锦丹_基于文献知识单元的知识组织——文献知识库建设研究.pdf:files/39/2002_曹锦丹_基于文献知识单元的知识组织——文献知识库建设研究.pdf:application/pdf}
}

@inproceedings{siochos_developing_2011,
	title = {Developing a {Formal} {Model} for {Mind} {Maps}},
	url = {http://eprints.rclis.org/15842/},
	abstract = {Mind map is a graphical technique, which is used to represent words, concepts, tasks or other connected items or arranged around central topic or idea. Mind maps are widely used, therefore exist plenty of software programs to create or edit them, while there is none format for the model representation, neither a standard format. This paper presents and effort to propose a formal mind map model aiming to describe the structure, content, semantics and social connections. The structure describes the basic mind map graph consisted of a node set, an edge set, a cloud set and a graphical connections set. The content includes the set of the texts and objects linked to the nodes. The social connections are the mind maps of other users, which form the neighborhood of the mind map owner in a social networking system. Finally, the mind map semantics is any true logic connection between mind map textual parts and a concept. Each of these elements of the model is formally described building the suggested mind map model. Its establishment will support the application of algorithms and methods towards their information extraction.},
	urldate = {2016-03-29},
	author = {Siochos, Vasilis and Papatheodorou, Christos},
	month = mar,
	year = {2011},
	pages = {39--44},
	file = {2011_Siochos_Papatheodorou_Developing a Formal Model for Mind Maps.pdf:files/53/2011_Siochos_Papatheodorou_Developing a Formal Model for Mind Maps.pdf:application/pdf}
}

@article{dey_conceptual_2001,
	title = {A {Conceptual} {Framework} and a {Toolkit} for {Supporting} the {Rapid} {Prototyping} of {Context}-{Aware} {Applications}},
	volume = {16},
	issn = {0737-0024},
	url = {http://www.informaworld.com/openurl?genre=article&doi=10.1207/S15327051HCI16234_02&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
	doi = {10.1207/S15327051HCI16234_02},
	language = {en},
	number = {2},
	urldate = {2016-04-05},
	journal = {Human-Computer Interaction},
	author = {Dey, Anind and Abowd, Gregory and Salber, Daniel},
	month = dec,
	year = {2001},
	pages = {97--166}
}

@article{__2010,
	title = {基于主题图的文献资源组织模型及应用研究},
	volume = {38},
	abstract = {文章分析了主题图的相关理论和传统文献组织方法优劣,论证了主题图在文献资源组织中的可行性,提出了基于主题图的文献资源组织模型及构建方法,引申了基于该模型的文献检索、主题导学、个性化资源推荐等应用研究。},
	number = {10},
	journal = {《计算机与数字工程》},
	author = {白, 新国 and 曲, 蕴慧},
	year = {2010},
	pages = {47--49},
	file = {2010_白_曲_基于主题图的文献资源组织模型及应用研究.pdf:files/48/2010_白_曲_基于主题图的文献资源组织模型及应用研究.pdf:application/pdf}
}

@book{__2002-1,
	title = {概念图的知识及其研究综述},
	volume = {10},
	url = {http://www.fjzzjy.gov.cn/images/uploadfiles/20070419094134.doc},
	number = {33},
	urldate = {2016-04-02},
	author = {{朱学庆}},
	year = {2002}
}

@article{dourish_presto:_1999,
	title = {Presto: {An} {Experimental} {Architecture} for {Fluid} {Interactive} {Document} {Spaces}},
	volume = {6},
	issn = {1073-0516},
	shorttitle = {Presto},
	url = {http://doi.acm.org/10.1145/319091.319099},
	doi = {10.1145/319091.319099},
	abstract = {Traditional document systems use hierarchical filing structures as the basis for organizing, storing and retrieving documents. However, this structure is very limited in comparison with the rich and varied forms of document interaction and category management in everyday document use. Presto is a prototype document management system providing rich interaction with documents through meaningful, user-level document attributes, such as “Word file,” “published paper,” “shared with Jim,” “about Presto,” or “currently in progress” Document attributes capture the multiple different roles that a single document might play, and they allow users to rapidly reorganize their document space for the task at hand. They also provide a basis  for novel document systems design and new approaches to document management and interaction. In this article, we outline the motivations behind this approach, describe the principal components of our implementation, discuss architectural consequences, and show how these support new forms of interactions with large personal document spaces.},
	number = {2},
	urldate = {2016-04-08},
	journal = {ACM Trans. Comput.-Hum. Interact.},
	author = {Dourish, Paul and Edwards, W. Keith and LaMarca, Anthony and Salisbury, Michael},
	month = jun,
	year = {1999},
	keywords = {attribute/value systems, direct manipulation, document management},
	pages = {133--161},
	file = {1999_Dourish et al_Presto.pdf:files/32/1999_Dourish et al_Presto.pdf:application/pdf}
}

@article{__2006,
	title = {知识组织的方式方法研究综述},
	url = {http://www.cqvip.com/qk/97427a/200602/21445137.html},
	number = {2},
	urldate = {2016-04-02},
	journal = {新世纪图书馆},
	author = {{李桂贞} and {郑建明}},
	year = {2006},
	pages = {7--10},
	file = {2006_李桂贞_郑建明_知识组织的方式方法研究综述.pdf:files/30/2006_李桂贞_郑建明_知识组织的方式方法研究综述.pdf:application/pdf}
}

@article{garshol_metadata?_2004,
	title = {Metadata? {Thesauri}? {Taxonomies}? {Topic} {Maps}! {Making} {Sense} of it all},
	volume = {30},
	issn = {0165-5515, 1741-6485},
	shorttitle = {Metadata?},
	url = {http://jis.sagepub.com/content/30/4/378},
	doi = {10.1177/0165551504045856},
	abstract = {To be faced with a document collection and not to be able to find the information you know exists somewhere within it is a problem as old as the existence of document collections. Information architecture is the discipline dealing with the modern version of this problem: how to organize web sites so that users can actually find what they are looking for. Information architects have so far applied known and well-tried tools from library science to solve this problem, and now topic maps are sailing up as another potential tool for information architects. This raises the question of how topic maps compare with the traditional solutions, and that is the question this paper attempts to address. The paper argues that topic maps go beyond the traditional solutions in the sense that they provide a framework within which they can be represented as they are, but also extended in ways which significantly improve information retrieval.},
	language = {en},
	number = {4},
	urldate = {2016-04-03},
	journal = {Journal of Information Science},
	author = {Garshol, Lars Marius},
	month = aug,
	year = {2004},
	keywords = {classification, comparative studies, information organization, information retrieval, metadata, ontologies, subject searching, taxonomies, thesauri, topic maps, web sites, world wide web},
	pages = {378--391},
	annote = {用dublin core（标题等基础信息）不是特别有效
keyword最有用
 },
	file = {2004_Garshol_Metadata.pdf:files/34/2004_Garshol_Metadata.pdf:application/pdf}
}

@article{__2006-1,
	title = {基于主题地图的文献组织方法研究},
	volume = {13},
	url = {http://www.cqvip.com/qk/87801x/200720/25620960.html},
	number = {20},
	urldate = {2016-04-03},
	journal = {中国学术期刊文摘},
	author = {田海燕},
	year = {2006},
	pages = {279--279},
	file = {2007_吴江宁_基于主题地图的文献组织方法研究.pdf:files/50/2007_吴江宁_基于主题地图的文献组织方法研究.pdf:application/pdf}
}

@inproceedings{cuadros_point_2007,
	title = {Point {Placement} by {Phylogenetic} {Trees} and its {Application} to {Visual} {Analysis} of {Document} {Collections}},
	doi = {10.1109/VAST.2007.4389002},
	abstract = {The task of building effective representations to visualize and explore collections with moderate to large number of documents is hard. It depends on the evaluation of some distance measure among texts and also on the representation of such relationships in bi- dimensional spaces. In this paper we introduce an alternative approach for building visual maps of documents based on their content similarity, through reconstruction of phylogenetic trees. The tree is capable of representing relationships that allows the user to quickly recover information detected by the similarity metric. For a variety of text collections of different natures we show that we can achieve improved exploration capability and more clear visualization of relationships amongst documents.},
	booktitle = {{IEEE} {Symposium} on {Visual} {Analytics} {Science} and {Technology}, 2007. {VAST} 2007},
	author = {Cuadros, A. M. and Paulovich, F. V. and Minghim, R. and Telles, G. P.},
	month = oct,
	year = {2007},
	keywords = {Computer graphics, data visualisation, Document Analysis, document representation, document visualization, Electronic mail, Extraterrestrial measurements, Internet, Multidimensional systems, Multidimensional Visualization, Phylogenetic Trees, phylogenetic trees point placement, Phylogeny, text analysis, Text Analytics, Text processing, textual document collection, tree data structures, Visual databases, Visualization, visual map analysis},
	pages = {99--106},
	file = {2007_Cuadros et al_Point Placement by Phylogenetic Trees and its Application to Visual Analysis of.pdf:files/49/2007_Cuadros et al_Point Placement by Phylogenetic Trees and its Application to Visual Analysis of.pdf:application/pdf}
}

@article{davies_concept_2010,
	title = {Concept mapping, mind mapping and argument mapping: what are the differences and do they matter?},
	volume = {62},
	issn = {0018-1560, 1573-174X},
	shorttitle = {Concept mapping, mind mapping and argument mapping},
	url = {http://link.springer.com/article/10.1007/s10734-010-9387-6},
	doi = {10.1007/s10734-010-9387-6},
	abstract = {In recent years, academics and educators have begun to use software mapping tools for a number of education-related purposes. Typically, the tools are used to help impart critical and analytical skills to students, to enable students to see relationships between concepts, and also as a method of assessment. The common feature of all these tools is the use of diagrammatic relationships of various kinds in preference to written or verbal descriptions. Pictures and structured diagrams are thought to be more comprehensible than just words, and a clearer way to illustrate understanding of complex topics. Variants of these tools are available under different names: “concept mapping”, “mind mapping” and “argument mapping”. Sometimes these terms are used synonymously. However, as this paper will demonstrate, there are clear differences in each of these mapping tools. This paper offers an outline of the various types of tool available and their advantages and disadvantages. It argues that the choice of mapping tool largely depends on the purpose or aim for which the tool is used and that the tools may well be converging to offer educators as yet unrealised and potentially complementary functions.},
	language = {en},
	number = {3},
	urldate = {2016-03-29},
	journal = {Higher Education},
	author = {Davies, Martin},
	month = nov,
	year = {2010},
	keywords = {Argument, Computer-aided argument mapping, Concept mapping, Critical thinking, Higher Education, Inference-making, Knowledge mapping, Mind mapping},
	pages = {279--301},
	file = {2010_Davies_Concept mapping, mind mapping and argument mapping.pdf:files/41/2010_Davies_Concept mapping, mind mapping and argument mapping.pdf:application/pdf}
}

@article{dourish_extending_2000,
	title = {Extending {Document} {Management} {Systems} with {User}-specific {Active} {Properties}},
	volume = {18},
	issn = {1046-8188},
	url = {http://doi.acm.org/10.1145/348751.348758},
	doi = {10.1145/348751.348758},
	abstract = {Document properties are a compelling infrastructure on which to develop document management applications. A property-based approach avoids many of the problems of traditional heierarchical storage mechanisms, reflects document organizations meaningful to user tasks, provides a means to integrate the perspectives of multiple individuals and groups, and does this all within a uniform interaction framework. Document properties can reflect not only categorizations of documents and document use, but also expressions of desired system activity, such as sharing criteria, replication management, and versioning. Augmenting property-based document management systems with active properties that carry executable code enables the provision of document-based services on a property infrastructure.   The combination of document properties as a uniform mechanism for document management, and active properties as a way of delivering document services, represents a new paradigm for document management infrastructures. The Placeless Documents system is an experimental prototype developed to explore this new paradigm. It is based on the seamless integration of user-specific, active properties. We present the fundamental design approach, explore the challenges and opportunities it presents, and show our architectures deals with them.},
	number = {2},
	urldate = {2016-04-02},
	journal = {ACM Trans. Inf. Syst.},
	author = {Dourish, Paul and Edwards, W. Keith and LaMarca, Anthony and Lamping, John and Petersen, Karin and Salisbury, Michael and Terry, Douglas B. and Thornton, James},
	month = apr,
	year = {2000},
	keywords = {active properties, component software, document management systems, document services, user experience},
	pages = {140--170},
	file = {2000_Dourish et al_Extending Document Management Systems with User-specific Active Properties.pdf:files/37/2000_Dourish et al_Extending Document Management Systems with User-specific Active Properties.pdf:application/pdf}
}

@article{eppler_comparison_2006-1,
	title = {A {Comparison} between {Concept} {Maps}, {Mind} {Maps}, {Conceptual} {Diagrams}, and {Visual} {Metaphors} as {Complementary} {Tools} for {Knowledge} {Construction} and {Sharing}},
	volume = {5},
	issn = {1473-8716, 1473-8724},
	url = {http://ivi.sagepub.com/content/5/3/202},
	doi = {10.1057/palgrave.ivs.9500131},
	abstract = {In this article, Novak's concept mapping technique is compared to three other types of visualization formats, namely mind maps, conceptual diagrams, and visual metaphors. The application parameters and the respective advantages and disadvantages of each format for learning and knowledge sharing are reviewed and discussed. It is argued that the combination of these four visualization types can play to the strength of each one. The article then provides real-life examples from such a use in undergraduate and graduate university teaching. The results provide first indications that the different visualization formats can be used in complementary ways to enhance motivation, attention, understanding and recall. The implications for a complementary use of these visualization formats in class room and meeting contexts are discussed and a future research agenda in this domain is articulated.},
	language = {en},
	number = {3},
	urldate = {2016-04-18},
	journal = {Information Visualization},
	author = {Eppler, Martin J.},
	month = sep,
	year = {2006},
	keywords = {complementary visualization, Concept map, concept skeleton, conceptual diagram, mind map, visual metaphor},
	pages = {202--210},
	file = {Eppler_2006_A Comparison between Concept Maps, Mind Maps, Conceptual Diagrams, and Visual.pdf:files/62/Eppler_2006_A Comparison between Concept Maps, Mind Maps, Conceptual Diagrams, and Visual.pdf:application/pdf}
}

@article{wheeldon_mapping_2010,
	title = {Mapping {Mixed} {Methods} {Research}: {Methods}, {Measures}, and {Meaning}},
	volume = {4},
	issn = {1558-6898, 1558-6901},
	shorttitle = {Mapping {Mixed} {Methods} {Research}},
	url = {http://mmr.sagepub.com/content/4/2/87},
	doi = {10.1177/1558689809358755},
	abstract = {This article explores how concept maps and mind maps can be used as data collection tools in mixed methods research to combine the clarity of quantitative counts with the nuance of qualitative reflections. Based on more traditional mixed methods approaches, this article details how the use of pre/post concept maps can be used to design qualitative interviews. As a more novel contribution, this article also explores how qualitative participant-generated mind maps can be used in multistage data collection to develop a mixed methods ‘‘salience score.’’ Although in many ways preliminary, this approach offers an initial means to consider on what basis a mixed methods measure could be conceived.},
	language = {en},
	number = {2},
	urldate = {2016-04-18},
	journal = {Journal of Mixed Methods Research},
	author = {Wheeldon, J.},
	month = apr,
	year = {2010},
	keywords = {abduction, concept maps, data collection, mind maps, mixed methods measure, pragmatism},
	pages = {87--102},
	file = {Snapshot:files/65/87.html:text/html;Wheeldon_2010_Mapping Mixed Methods Research.pdf:files/66/Wheeldon_2010_Mapping Mixed Methods Research.pdf:application/pdf}
}