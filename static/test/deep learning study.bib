@article{bengio_representation_2013,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	volume = {35},
	issn = {0162-8828},
	shorttitle = {Representation {Learning}},
	doi = {10.1109/TPAMI.2013.50},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bengio, Y. and Courville, A. and Vincent, P.},
	month = aug,
	year = {2013},
	keywords = {Abstracts, AI, Algorithms, artificial intelligence, autoencoder, autoencoders, Boltzmann machine, data representation, data structures, Deep learning, density estimation, Feature extraction, feature learning, geometrical connections, Humans, Learning systems, Machine learning, machine learning algorithms, manifold learning, Manifolds, neural nets, Neural networks, Neural Networks (Computer), probabilistic models, probability, representation learning, Speech recognition, unsupervised feature learning, unsupervised learning},
	pages = {1798--1828},
	file = {2013_Bengio et al_Representation Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2013\\2013_Bengio et al_Representation Learning.pdf:application/pdf}
}

@misc{_convolutional_2016,
	title = {Convolutional neural network},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&oldid=715827194},
	abstract = {In machine learning, a convolutional neural network (CNN, or ConvNet) is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex, whose individual neurons are arranged in such a way that they respond to overlapping regions tiling the visual field. Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons designed to use minimal amounts of preprocessing. They have wide applications in image and video recognition, recommender systems and natural language processing.},
	language = {en},
	urldate = {2016-04-19},
	journal = {Wikipedia, the free encyclopedia},
	month = apr,
	year = {2016},
	note = {Page Version ID: 715827194},
	file = {Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\EXR2JBU4\\index.html:text/html}
}

@article{schmidhuber_deep_2015,
	title = {Deep learning in neural networks: {An} overview},
	volume = {61},
	issn = {0893-6080},
	shorttitle = {Deep learning in neural networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2016-05-01},
	journal = {Neural Networks},
	author = {Schmidhuber, Jürgen},
	month = jan,
	year = {2015},
	keywords = {Deep learning, Evolutionary computation, Reinforcement learning, Supervised learning, unsupervised learning},
	pages = {85--117},
	file = {Schmidhuber_2015_Deep learning in neural networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2015\\Schmidhuber_2015_Deep learning in neural networks.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\ADW9HS9I\\S0893608014002135.html:text/html}
}

@article{srivastava_dropout:_2014,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overfitting}},
	volume = {15},
	issn = {1532-4435},
	shorttitle = {Dropout},
	url = {http://dl.acm.org/citation.cfm?id=2627435.2670313},
	abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
	number = {1},
	urldate = {2016-05-01},
	journal = {J. Mach. Learn. Res.},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	month = jan,
	year = {2014},
	keywords = {Deep learning, model combination, Neural networks, regularization},
	pages = {1929--1958},
	file = {Srivastava et al_2014_Dropout.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2014\\Srivastava et al_2014_Dropout.pdf:application/pdf}
}

@incollection{dosovitskiy_discriminative_2014,
	title = {Discriminative {Unsupervised} {Feature} {Learning} with {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf},
	urldate = {2016-05-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Dosovitskiy, Alexey and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {766--774},
	file = {Dosovitskiy et al_2014_Discriminative Unsupervised Feature Learning with Convolutional Neural Networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2014\\Dosovitskiy et al_2014_Discriminative Unsupervised Feature Learning with Convolutional Neural Networks.pdf:application/pdf;NIPS Snapshort:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\4GG8JAUF\\5548-active-regression-by-stratification.html:text/html}
}

@inproceedings{lee_convolutional_2009,
	address = {New York, NY, USA},
	series = {{ICML} '09},
	title = {Convolutional {Deep} {Belief} {Networks} for {Scalable} {Unsupervised} {Learning} of {Hierarchical} {Representations}},
	isbn = {978-1-60558-516-1},
	url = {http://doi.acm.org/10.1145/1553374.1553453},
	doi = {10.1145/1553374.1553453},
	abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
	urldate = {2016-05-01},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
	year = {2009},
	pages = {609--616},
	file = {Lee et al_2009_Convolutional Deep Belief Networks for Scalable Unsupervised Learning of.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2009\\Lee et al_2009_Convolutional Deep Belief Networks for Scalable Unsupervised Learning of.pdf:application/pdf}
}

@article{lecun_generalization_1989,
	title = {Generalization and network design strategies},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.476.479&rep=rep1&type=pdf},
	urldate = {2016-05-01},
	journal = {Connections in Perspective. North-Holland, Amsterdam},
	author = {LeCun, Yann and {others}},
	year = {1989},
	pages = {143--55},
	file = {LeCun_others_1989_Generalization and network design strategies.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\1989\\LeCun_others_1989_Generalization and network design strategies.pdf:application/pdf}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2016-05-01},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105},
	file = {Krizhevsky et al_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2012\\Krizhevsky et al_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:application/pdf;NIPS Snapshort:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\27S6CPK5\\4824-imagenet-classification-w.html:text/html}
}

@article{hinton_improving_2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	url = {http://arxiv.org/abs/1207.0580},
	abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
	urldate = {2016-05-01},
	journal = {arXiv:1207.0580 [cs]},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	month = jul,
	year = {2012},
	note = {arXiv: 1207.0580},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\RK3II57N\\1207.html:text/html;Hinton et al_2012_Improving neural networks by preventing co-adaptation of feature detectors.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2012\\Hinton et al_2012_Improving neural networks by preventing co-adaptation of feature detectors.pdf:application/pdf}
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {2D shape variability, Backpropagation, back-propagation, Character recognition, cheque reading, complex decision surface synthesis, Convolution, convolutional neural network character recognizers, document recognition, document recognition systems, Feature extraction, field extraction, gradient-based learning, gradient based learning technique, graph transformer networks, GTN, handwritten character recognition, handwritten digit recognition task, Hidden Markov models, high-dimensional patterns, language modeling, Machine learning, Multi-layer neural network, multilayer neural networks, multilayer perceptrons, multimodule systems, Neural networks, Optical character recognition, Optical character recognition software, Optical computing, Pattern recognition, performance measure minimization, Principal component analysis, segmentation recognition},
	pages = {2278--2324},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\M25PQNGT\\abs_all.html:text/html;Lecun et al_1998_Gradient-based learning applied to document recognition.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\1998\\Lecun et al_1998_Gradient-based learning applied to document recognition.pdf:application/pdf}
}

@article{arel_deep_2010,
	title = {Deep {Machine} {Learning} - {A} {New} {Frontier} in {Artificial} {Intelligence} {Research} [{Research} {Frontier}]},
	volume = {5},
	issn = {1556-603X},
	doi = {10.1109/MCI.2010.938364},
	abstract = {This article provides an overview of the mainstream deep learning approaches and research directions proposed over the past decade. It is important to emphasize that each approach has strengths and "weaknesses, depending on the application and context in "which it is being used. Thus, this article presents a summary on the current state of the deep machine learning field and some perspective into how it may evolve. Convolutional Neural Networks (CNNs) and Deep Belief Networks (DBNs) (and their respective variations) are focused on primarily because they are well established in the deep learning field and show great promise for future work.},
	number = {4},
	journal = {IEEE Computational Intelligence Magazine},
	author = {Arel, I. and Rose, D. C. and Karnowski, T. P.},
	month = nov,
	year = {2010},
	keywords = {artificial intelligence research, belief networks, CNN, Convolutional neural networks, DBN, deep belief networks, deep machine learning approach, learning (artificial intelligence), neural nets},
	pages = {13--18},
	file = {Arel et al_2010_Deep Machine Learning - A New Frontier in Artificial Intelligence Research.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Arel et al_2010_Deep Machine Learning - A New Frontier in Artificial Intelligence Research.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\97CI5236\\abs_all.html:text/html}
}

@article{bengio_representation_2012,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	shorttitle = {Representation {Learning}},
	url = {http://arxiv.org/abs/1206.5538},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	urldate = {2016-05-01},
	journal = {arXiv:1206.5538 [cs]},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.5538},
	keywords = {Computer Science - Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\PTAWIH8C\\1206.html:text/html;Bengio et al_2012_Representation Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2012\\Bengio et al_2012_Representation Learning.pdf:application/pdf}
}

@inproceedings{nair_rectified_2010,
	title = {Rectified linear units improve restricted boltzmann machines},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_NairH10.pdf},
	urldate = {2016-05-01},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Machine} {Learning} ({ICML}-10)},
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	year = {2010},
	pages = {807--814},
	file = {Nair_Hinton_2010_Rectified linear units improve restricted boltzmann machines.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Nair_Hinton_2010_Rectified linear units improve restricted boltzmann machines.pdf:application/pdf}
}

@inproceedings{carreira-perpinan_contrastive_2005,
	title = {On {Contrastive} {Divergence} {Learning}.},
	volume = {10},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829&rep=rep1&type=pdf#page=42},
	urldate = {2016-05-01},
	booktitle = {{AISTATS}},
	publisher = {Citeseer},
	author = {Carreira-Perpinan, Miguel A. and Hinton, Geoffrey},
	year = {2005},
	pages = {33--40},
	file = {Carreira-Perpinan_Hinton_2005_On Contrastive Divergence Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2005\\Carreira-Perpinan_Hinton_2005_On Contrastive Divergence Learning.pdf:application/pdf}
}

@article{bengio_learning_1994,
	title = {Learning long-term dependencies with gradient descent is difficult},
	volume = {5},
	issn = {1045-9227},
	doi = {10.1109/72.279181},
	abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered},
	number = {2},
	journal = {IEEE Transactions on Neural Networks},
	author = {Bengio, Y. and Simard, P. and Frasconi, P.},
	month = mar,
	year = {1994},
	keywords = {Computer networks, Cost function, Delay effects, Discrete transforms, Displays, efficient learning, gradient descent, input/output sequence mapping, Intelligent networks, learning (artificial intelligence), long-term dependencies, Neural networks, Neurofeedback, numerical analysis, prediction problems, Production, production problems, recognition, recurrent neural nets, Recurrent neural networks, recurrent neural network training, temporal contingencies},
	pages = {157--166},
	file = {Bengio et al_1994_Learning long-term dependencies with gradient descent is difficult.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\1994\\Bengio et al_1994_Learning long-term dependencies with gradient descent is difficult.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\W5IRGBDJ\\abs_all.html:text/html}
}

@article{bengio_learning_2009,
	title = {Learning deep architectures for {AI}},
	volume = {2},
	url = {http://dl.acm.org/citation.cfm?id=1658424},
	number = {1},
	urldate = {2016-05-01},
	journal = {Foundations and trends® in Machine Learning},
	author = {Bengio, Yoshua},
	year = {2009},
	pages = {1--127},
	file = {Bengio_2009_Learning deep architectures for AI.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2009\\Bengio_2009_Learning deep architectures for AI.pdf:application/pdf;Snapshot:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\V3SH6FWC\\citation.html:text/html}
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf},
	urldate = {2016-05-01},
	booktitle = {International conference on artificial intelligence and statistics},
	author = {Glorot, Xavier and Bengio, Yoshua},
	year = {2010},
	pages = {249--256},
	file = {Glorot_Bengio_2010_Understanding the difficulty of training deep feedforward neural networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Glorot_Bengio_2010_Understanding the difficulty of training deep feedforward neural networks.pdf:application/pdf}
}

@inproceedings{jarrett_what_2009,
	title = {What is the best multi-stage architecture for object recognition?},
	doi = {10.1109/ICCV.2009.5459469},
	abstract = {In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63\% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6\%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 ({\textgreater} 65\%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53\%).},
	booktitle = {2009 {IEEE} 12th {International} {Conference} on {Computer} {Vision}},
	author = {Jarrett, K. and Kavukcuoglu, K. and Ranzato, M. and LeCun, Y.},
	month = sep,
	year = {2009},
	keywords = {Brain modeling, Caltech-101, Error analysis, Feature extraction, feature pooling layer, feature rectification, filter bank, Gabor filters, Histograms, Image edge detection, Learning systems, local contrast normalization, multistage architecture, nonlinear transformation, NORB dataset, object recognition, Refining, Supervised learning, unprocessed MNIST dataset, unsupervised learning},
	pages = {2146--2153},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\4826BN4G\\abs_all.html:text/html;Jarrett et al_2009_What is the best multi-stage architecture for object recognition.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2009\\Jarrett et al_2009_What is the best multi-stage architecture for object recognition.pdf:application/pdf}
}

@article{erhan_why_2010,
	title = {Why {Does} {Unsupervised} {Pre}-training {Help} {Deep} {Learning}?},
	volume = {11},
	issn = {1532-4435},
	url = {http://dl.acm.org/citation.cfm?id=1756006.1756025},
	abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.},
	urldate = {2016-05-01},
	journal = {J. Mach. Learn. Res.},
	author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
	month = mar,
	year = {2010},
	pages = {625--660},
	file = {Erhan et al_2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2010\\Erhan et al_2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:application/pdf}
}

@article{farabet_learning_2013,
	title = {Learning {Hierarchical} {Features} for {Scene} {Labeling}},
	volume = {35},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2012.231},
	abstract = {Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320×240 image labeling in less than a second, including feature extraction.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Farabet, C. and Couprie, C. and Najman, L. and LeCun, Y.},
	month = aug,
	year = {2013},
	keywords = {Accuracy, Barcelona dataset, Context, contextual information capturing, Convolutional networks, Deep learning, dense feature vector extraction, Feature extraction, hierarchical feature learning, image classification, Image edge detection, image labeling, image pixel labeling, image segmentation, image texture, Labeling, multiple size region encoding, multiscale convolutional network, near-record accuracy, object category, scene labeling, scene parsing, segmentation components, segmentation tree, shape information capturing, shape recognition, SIFT flow dataset, Stanford background dataset, texture information capturing, transforms, trees (mathematics), Vectors},
	pages = {1915--1929},
	file = {Farabet et al_2013_Learning Hierarchical Features for Scene Labeling.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2013\\Farabet et al_2013_Learning Hierarchical Features for Scene Labeling.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\EACH\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\j2jwlmdq.default\\zotero\\storage\\6268BX6T\\abs_all.html:text/html}
}

@article{bengio_greedy_2007,
	title = {Greedy layer-wise training of deep networks},
	volume = {19},
	url = {https://books.google.com/books?hl=zh-CN&lr=&id=Tbn1l9P1220C&oi=fnd&pg=PA153&dq=greedy+layer-wise+training+of+deep+networks&ots=V3q8Bmps3_&sig=TY9bt9KZNBh4yfiH-PiKCD4JR6s},
	urldate = {2016-05-01},
	journal = {Advances in neural information processing systems},
	author = {Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo and {others}},
	year = {2007},
	pages = {153},
	file = {Bengio et al_2007_Greedy layer-wise training of deep networks.pdf:D\:\\百度云同步\\论文\\zotero\\storage\\2007\\Bengio et al_2007_Greedy layer-wise training of deep networks.pdf:application/pdf}
}